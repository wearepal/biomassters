# @package _global_

defaults:
    - override /model: unet3d_im/efficient
    - override /dm: all_months/zscore_norm
    - override /alg: erm
    - override /logger: pal
    - override /checkpointer: bio
    - _self_

trainer:
  precision: 16
  max_steps: ${eval:'30000 * ${trainer.accumulate_grad_batches}'}
  val_check_interval: ${eval:'500 * ${trainer.accumulate_grad_batches}'}
  accumulate_grad_batches: 4
  accelerator: gpu
  devices: 4
  strategy: 
    _target_: pytorch_lightning.strategies.DeepSpeedStrategy
    stage: 2
    offload_optimizer: false
    offload_parameters: false
    min_loss_scale: 1

alg:
  pred_dir: /srv/galene0/shared/data/biomassters/predictions/unet3d/${EPOCHSECONDS}
  lr: 3e-4
  lr_sched_freq: 1
  test_on_best: false
  loss_fn: 
    _target_: torch.nn.HuberLoss
    delta: 1.0

  optimizer_cls: deepspeed.ops.adam.FusedAdam
  weight_decay: 0.0

  scheduler_cls: ranzen.torch.schedulers.CosineLRWithLinearWarmup
  scheduler_kwargs:
    warmup_iters: ${eval:'2000 * ${trainer.accumulate_grad_batches}'}
    total_iters: ${eval:'${trainer.max_steps} // ${trainer.accumulate_grad_batches}'}
    lr_min: 5.0e-7

dm:
  num_workers: 24
  train_batch_size: 2

logger:
  group: unet3d_imagen_efficient
  tags:
    - base_dim_128
    - attn_head_dim_64
    - no_spatial_attn
    - unet3d_imagen
    - zscore_norm
    - linear_warmup

